for(i in 1:length(levels(df$CLASS)))
res[[i]]= tryCatch({df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve},error=function(r) NA)
#res[[i]]=df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve
res
}
#расстояния Махаланобиса от элемента до каждого из классов
distance=function(means,covs, elem){
res=c()
for(i in 1:nrow(means)){
vec=(means[i,]-elem)
res[i]=(vec%*%covs[[i]])%*%vec
}
return(sqrt(res))
}
#поиск номера элемента в датафрейме
find.number=function(df,elem){
sm=0
i=0
len=length(elem)
while (sm!=len) {
i=i+1
v=ifelse(df[i,]==elem,T,F)
sm=sum(v)
}
return(i)
}
acc=0#точность
repeat{
#for(k in 1:40){
#showfaces()
showimage()
ldadat <- lda(CLASS~.,data,method="moment")
means=ldadat$means
cov.mat=covinv(data)
#для всех неправильно найденных найти расстояния до кластеров, отнесённых экспертами
prclass=predict(ldadat, data[,1:7])$class
st=data[data$CLASS!=prclass,]
acc=1-nrow(st)/nrow(data)
cat("Точность классификации:",acc,'\n')
if(near(acc,1)) break
if(nrow(st)==1){
number.of.max.distance=1
}else{
distances=c()
for(i in 1:nrow(st)){
cls=as.numeric(st[i,8])
vec=(means[cls,]-as.numeric(st[i,1:7]))
if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
ldadat$means#групповые средние
(mat=ldadat$scaling)#матрица дискриминантных функций
plot(ldadat)
#линейный дискриминантный анализ
ldadat <- lda(CLASS~.,data,method="moment")
###################################Задание 4
data =data.frame(read_excel("Приложение 2.xlsx"))
data$CLASS=factor(data$CLASS)
pairs(data[,1:7],col=data$CLASS,pch=16)
#лица Чернова
showfaces=function(){
newdata=as_data_frame(data)%>%group_by(CLASS)%>%
summarise_all(funs(mean))
print(faces(newdata[,2:8]))#рисуем лица
}
showfaces()
#визуализация кластеров через главные компоненты
showimage=function(){
library(factoextra)
print( fviz_cluster(list(data=data[,1:7],cluster=data[,8]), ellipse.type = "norm"))
}
#проверка многомерного нормального распределения по каждому классу
tmp=numeric()
library(mvnormtest)
for(i in 1:length(levels(data$CLASS))){
tmp[i]=mshapiro.test(t(data[data$CLASS == i, 1:7]))$p.value
}
library(MASS)
# Функция вывода результатов классификации
Out_CTab <- function(model, group) {
cat("Таблица неточностей \"Факт/Прогноз\" по обучающей выборке: \n")
classified <- predict(model)$class
t1 <- table(group, classified)
print(t1)
# Точность классификации и расстояние Махалонобиса
Err_S <- mean(group != classified)
mahDist <- dist(model$means %*% model$scaling)
cat("Точность классификации:",1-Err_S[1],'\n')
cat("Расстояния Махалонобиса:\n")
print(mahDist)
# Таблица "Факт/Прогноз" и ошибка при скользящем контроле
t2 <-  table(group, update(model, CV = T)$class -> LDA.cv)
Err_CV <- mean(group != LDA.cv)
cat("Ошибка при скользящем контроле:",Err_CV[1],'\n')
Err_S.MahD <- c(Err_S, mahDist)
Err_CV.N <- c(Err_CV, length(group))
cbind(t1, Err_S.MahD, t2, Err_CV.N)
cat("Результаты многомерного дисперсионного анализа: \n")
ldam <- manova(as.matrix( data[,1:7]) ~ data$CLASS)
print(summary(ldam, test="Wilks"))
}
#линейный дискриминантный анализ
ldadat <- lda(CLASS~.,data,method="moment")
Out_CTab(ldadat,data$CLASS)
Out_CTab(ldadat,data$CLASS)
ldadat$means#групповые средние
(mat=ldadat$scaling)#матрица дискриминантных функций
plot(ldadat)
#матрицы, обратные матрицам ковариации для каждого класса
covinv=function(df){
res=list()
for(i in 1:length(levels(df$CLASS)))
res[[i]]= tryCatch({df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve},error=function(r) NA)
#res[[i]]=df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve
res
}
#расстояния Махаланобиса от элемента до каждого из классов
distance=function(means,covs, elem){
res=c()
for(i in 1:nrow(means)){
vec=(means[i,]-elem)
res[i]=(vec%*%covs[[i]])%*%vec
}
return(sqrt(res))
}
#поиск номера элемента в датафрейме
find.number=function(df,elem){
sm=0
i=0
len=length(elem)
while (sm!=len) {
i=i+1
v=ifelse(df[i,]==elem,T,F)
sm=sum(v)
}
return(i)
}
acc=0#точность
repeat{
#for(k in 1:40){
#showfaces()
showimage()
ldadat <- lda(CLASS~.,data,method="moment")
means=ldadat$means
cov.mat=covinv(data)
#для всех неправильно найденных найти расстояния до кластеров, отнесённых экспертами
prclass=predict(ldadat, data[,1:7])$class
st=data[data$CLASS!=prclass,]
acc=1-nrow(st)/nrow(data)
cat("Точность классификации:",acc,'\n')
if(near(acc,1)) break
if(nrow(st)==1){
number.of.max.distance=1
}else{
distances=c()
for(i in 1:nrow(st)){
cls=as.numeric(st[i,8])
vec=(means[cls,]-as.numeric(st[i,1:7]))
if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
#дерево классификации
library(tree)
datatree <- tree(data[,8] ~ ., data[,-8])
plot(datatree)
text(datatree)
knitr::opts_chunk$set(echo = TRUE,include = TRUE,tidy = TRUE,cache = FALSE,eval = TRUE, message = FALSE,warning = FALSE,fig.align = "center")
rf=lda(CLASS~.,data,method="moment")#фиксируется модель для следующего задания
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric)
data2=data2[31:80,]
(cluster=predict(rf, data2))
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric)
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric) %>% data_frame()
data2 =data.frame(read_excel("Приложение 3.xlsx"))
View(data2)
apply(data2,2,as.numeric)
apply(data2,2,as.numeric) %>% as_data_frame()
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric) %>% as_data_frame()
data2=data2[31:80,]
(cluster=predict(rf, data2))
data2=data.frame(cbind(data2,cluster))
data2$cluster=factor(data2$cluster)
cluster=predict(rf, data2)$cluster
cluster=predict(rf, data2)$class
data2=data.frame(cbind(data2,cluster))
data2$cluster=factor(data2$cluster)
View(data2)
View(data2)
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric) %>% as_data_frame()
data2=data2[31:80,]
(cluster=predict(rf, data2)$class)
data2=data.frame(cbind(data2,cluster))
data2$cluster=factor(data2$cluster)
newdata=as_data_frame(data2)%>%group_by(cluster)%>%
summarise_all(funs(mean))
View(newdata)
View(data)
faces(newdata[,2:8])#рисуем лица
View(newdata)
unlink('Многомерная статистика_cache', recursive = TRUE)
unlink('Многомерная статистика_cache', recursive = TRUE)
#Вариант 7
p1 = nchar("Дмитрий")
p2 = nchar("Пасько")
#Задание 1
library(readxl)
library(dplyr)
tab=data.frame(t(read_xlsx("Рожь18век.xlsx")))
names(tab)=sapply( tab[1,], as.character)#поставить правильные названия
tab=tab[-1,]#удалить строку с именами
tab=data.frame(Year=sapply(rownames(tab),as.numeric),tab)
tab=sapply(tab, as.numeric)#факторы перевести в числа
head(as_data_frame(tab),10)
tmptab=tab[,-1]
means=list(rowMeans(tmptab,na.rm = T))
for(i in 1:((ncol(tab)-1)/2)){
means[[i+1]]=rowMeans(tmptab[,c(i,i+1)],na.rm = T)
}
means=sapply(means,function(col)sapply(col, function(row) ifelse(is.nan(row),NA,row)))#Заменить все NaN на NA
means=data.frame(tab[,1],means)
names(means)=c("Год","ПоСтране","Район1","Район2","Район3","Район4","Район5","Район6","Район7","Район8","Район9")
head(means)
library(ggplot2)
p1=  ggplot(means,aes(x=Год))+
geom_line(aes(y=ПоСтране),size=1)
p2=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район1),size=1,col=2)
p3=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район2),size=1,col=3)
p4=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район3),size=1,col=5)
p5=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район4),size=1,col=6)
p6= ggplot(means,aes(x=Год))+
geom_line(aes(y=Район5),size=1,col=7)
p7= ggplot(means,aes(x=Год))+
geom_line(aes(y=Район6),size=1,col=8)
p8=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район7),size=1,col=9)
p9=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район8),size=1,col=10)
p10=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район9),size=1,col=11)
library(ggpubr)
ggarrange(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,nrow=5,ncol=2)
if(FALSE){
library(readxl)
tab=data.frame(read_xlsx("Псевдоцены.xlsx"))
colnames(tab)=c("Price","Year","City","Distrinct")
tab$Year=factor(tab$Year)
tab$City=factor(tab$City)
tab$Distrinct=factor(tab$Distrinct)
library(dplyr)
tib=data_frame(tab)[[1]]
# по городам
tb=tib%>%select(Price,Year,City)%>%group_by(Year,City)%>%
summarise(mean=mean(Price))
ms=matrix(tb$mean,nrow=length(levels(tb$Year)))
ms= data.frame(ms)
colnames(ms)=levels(tb$City)
rownames(ms)=levels(tb$Year)
# по районам
tb=tib%>%select(Price,Year,Distrinct)%>%group_by(Year,Distrinct)%>%
summarise(mean=mean(Price))
ms=matrix(tb$mean,nrow=length(levels(tb$Year)))
ms= data.frame(ms)
colnames(ms)=levels(tb$Distrinct)
rownames(ms)=levels(tb$Year)
# по стране
tb=tib%>%select(Price,Year)%>%group_by(Year)%>%
summarise(mean=mean(Price))
ms=matrix(tb$mean,nrow=length(levels(tb$Year)))
ms= data.frame(ms)
colnames(ms)=c("mean")
rownames(ms)=levels(tb$Year)
library(ggplot2)
df=data.frame(time=as.numeric(levels(tb$Year)),price=ms$mean)
ggplot(df,
aes(time,price))+
geom_point(size=3)+
geom_smooth(method = lm,se=F)+
geom_smooth(method =loess,col="red")
}
#forma=ts(df$price,start = min( df$time),frequency = 1)
#plot(stl(forma, s.window = 21)$time.series,main="")
price1 = c(
40 + p1,43 + p1,40,80,
74,40 + p2,55 + p2,42 + p2,
42,50,40 + p2,43,43,
35 + p1,40 + p1,30,36 + p1,
50,30 + p1,29,45 + p1,
40,42,40,36,
50,30 + p1,24 + p2,
25 + p2,40,32 + p1,
30,20,30,25,32 + p2
)
summary(price1)#минимальные характеристики
t.test(price1)#тест Стьюдента для среднего
vart=sd(price1)/mean(price1)*100
cat("Коэффициент вариации равен",vart,"%\n")
#так как коэффициент вариации < 30%, выборка достаточно однородная
t.test(means[,2],price1)
#Задание 3
library(ggplot2)
yt=c(1133+ p1,	1222,	1354+ p1,	1389,	1342+ p2,	1377,	1491,	1684+ p2)
data=data.frame(time=1:length(yt),values=yt)
plot(data,type="b")
fit=lm(values~time,data)#создание модели
ggplot(data,aes(x=time,y=values))+
geom_point()+
geom_smooth(method=lm)
summary(fit)#информация о модели
cf=fit$coefficients#коэффициенты
View(fit)
#Задание 3
library(ggplot2)
yt=c(1133+ p1,	1222,	1354+ p1,	1389,	1342+ p2,	1377,	1491,	1684+ p2)
data=data.frame(time=1:length(yt),values=yt)
plot(data,type="b")
fit=lm(values~time,data)#создание модели
ggplot(data,aes(x=time,y=values))+
geom_point()+
geom_smooth(method=lm)
summary(fit)#информация о модели
cf=fit$coefficients#коэффициенты
#Вариант 7
p1 = nchar("Дмитрий")
p2 = nchar("Пасько")
#Задание 1
library(readxl)
library(dplyr)
tab=data.frame(t(read_xlsx("Рожь18век.xlsx")))
names(tab)=sapply( tab[1,], as.character)#поставить правильные названия
tab=tab[-1,]#удалить строку с именами
tab=data.frame(Year=sapply(rownames(tab),as.numeric),tab)
tab=sapply(tab, as.numeric)#факторы перевести в числа
head(as_data_frame(tab),10)
tmptab=tab[,-1]
means=list(rowMeans(tmptab,na.rm = T))
for(i in 1:((ncol(tab)-1)/2)){
means[[i+1]]=rowMeans(tmptab[,c(i,i+1)],na.rm = T)
}
means=sapply(means,function(col)sapply(col, function(row) ifelse(is.nan(row),NA,row)))#Заменить все NaN на NA
means=data.frame(tab[,1],means)
names(means)=c("Год","ПоСтране","Район1","Район2","Район3","Район4","Район5","Район6","Район7","Район8","Район9")
head(means)
library(ggplot2)
p1=  ggplot(means,aes(x=Год))+
geom_line(aes(y=ПоСтране),size=1)
p2=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район1),size=1,col=2)
p3=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район2),size=1,col=3)
p4=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район3),size=1,col=5)
p5=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район4),size=1,col=6)
p6= ggplot(means,aes(x=Год))+
geom_line(aes(y=Район5),size=1,col=7)
p7= ggplot(means,aes(x=Год))+
geom_line(aes(y=Район6),size=1,col=8)
p8=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район7),size=1,col=9)
p9=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район8),size=1,col=10)
p10=  ggplot(means,aes(x=Год))+
geom_line(aes(y=Район9),size=1,col=11)
library(ggpubr)
ggarrange(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,nrow=5,ncol=2)
if(FALSE){
library(readxl)
tab=data.frame(read_xlsx("Псевдоцены.xlsx"))
colnames(tab)=c("Price","Year","City","Distrinct")
tab$Year=factor(tab$Year)
tab$City=factor(tab$City)
tab$Distrinct=factor(tab$Distrinct)
library(dplyr)
tib=data_frame(tab)[[1]]
# по городам
tb=tib%>%select(Price,Year,City)%>%group_by(Year,City)%>%
summarise(mean=mean(Price))
ms=matrix(tb$mean,nrow=length(levels(tb$Year)))
ms= data.frame(ms)
colnames(ms)=levels(tb$City)
rownames(ms)=levels(tb$Year)
# по районам
tb=tib%>%select(Price,Year,Distrinct)%>%group_by(Year,Distrinct)%>%
summarise(mean=mean(Price))
ms=matrix(tb$mean,nrow=length(levels(tb$Year)))
ms= data.frame(ms)
colnames(ms)=levels(tb$Distrinct)
rownames(ms)=levels(tb$Year)
# по стране
tb=tib%>%select(Price,Year)%>%group_by(Year)%>%
summarise(mean=mean(Price))
ms=matrix(tb$mean,nrow=length(levels(tb$Year)))
ms= data.frame(ms)
colnames(ms)=c("mean")
rownames(ms)=levels(tb$Year)
library(ggplot2)
df=data.frame(time=as.numeric(levels(tb$Year)),price=ms$mean)
ggplot(df,
aes(time,price))+
geom_point(size=3)+
geom_smooth(method = lm,se=F)+
geom_smooth(method =loess,col="red")
}
#forma=ts(df$price,start = min( df$time),frequency = 1)
#plot(stl(forma, s.window = 21)$time.series,main="")
price1 = c(
40 + p1,43 + p1,40,80,
74,40 + p2,55 + p2,42 + p2,
42,50,40 + p2,43,43,
35 + p1,40 + p1,30,36 + p1,
50,30 + p1,29,45 + p1,
40,42,40,36,
50,30 + p1,24 + p2,
25 + p2,40,32 + p1,
30,20,30,25,32 + p2
)
summary(price1)#минимальные характеристики
t.test(price1)#тест Стьюдента для среднего
vart=sd(price1)/mean(price1)*100
cat("Коэффициент вариации равен",vart,"%\n")
#так как коэффициент вариации < 30%, выборка достаточно однородная
t.test(means[,2],price1)
#Задание 3
library(ggplot2)
yt=c(1133+ p1,	1222,	1354+ p1,	1389,	1342+ p2,	1377,	1491,	1684+ p2)
data=data.frame(time=1:length(yt),values=yt)
plot(data,type="b")
fit=lm(values~time,data)#создание модели
ggplot(data,aes(x=time,y=values))+
geom_point()+
geom_smooth(method=lm)
summary(fit)#информация о модели
cf=fit$coefficients#коэффициенты
#прогноз среднего
predict(fit,data.frame(time = c(9)), se.fit=TRUE, interval="confidence", level=0.95)$fit
#прогноз индивидуального
predict(fit,data.frame(time = c(9)), se.fit=TRUE, interval="prediction", level=0.95)$fit
forma=ts(yt, start = 1,frequency = 1)
plot(stl(forma,s.window = "periodic")$time.series,main="")
yt=c(1133+ p1,	1222,	1354+ p1,	1389,	1342+ p2,	1377,	1491,	1684+ p2)
yt=c(1133+ p1,1222,1354+ p1,1389,1342+ p2,1377,1491,1684+ p2)
yt=c(1133+p1,1222,1354+p1,1389,1342+p2,1377,1491,1684+p2)
p1 = nchar("Дмитрий")
p2 = nchar("Пасько")
#Задание 3
library(ggplot2)
yt=c(1133+p1,1222,1354+p1,1389,1342+p2,1377,1491,1684+p2)
data=data.frame(time=1:length(yt),values=yt)
plot(data,type="b")
#Задание 3
library(ggplot2)
yt=c(1133+p1,1222,1354+p1,1389,1342+p2,1377,1491,1684+p2)
data=data.frame(time=1:length(yt),values=yt)
plot(data,type="b")
fit=lm(values~time,data)#создание модели
ggplot(data,aes(x=time,y=values))+
geom_point()+
geom_smooth(method=lm)
summary(fit)#информация о модели
cf=fit$coefficients#коэффициенты
anova(fit
)
anova(fit,levels(0.95))
anova(fit,levels(0.05))
exp(-166.5906)
qf(seq(0.92,0.99999999,length.out = 50),1,6)
qf(0.95,seq(1,10,10),seq(1,20,20))
install.packages("keras")
install.packages(c("caTools", "corrgram", "corrplot", "factoextra", "ggpubr", "mice", "randomForest", "TeachingDemos", "tree"))
