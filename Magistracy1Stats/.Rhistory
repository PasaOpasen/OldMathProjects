if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
###################################Задание 4
data =data.frame(read_excel("Приложение 2.xlsx"))
data$CLASS=factor(data$CLASS)
pairs(data[,1:7],col=data$CLASS,pch=16)
showfaces=function(){
newdata=as_data_frame(data)%>%group_by(CLASS)%>%
summarise_all(funs(mean))
print(faces(newdata[,2:8]))#рисуем лица
}
showfaces()
acc=0#точность
repeat{
#for(k in 1:40){
showfaces()
ldadat <- lda(CLASS~.,data,method="moment")
means=ldadat$means
cov.mat=covinv(data)
#для всех неправильно найденных найти расстояния до кластеров, отнесённых экспертами
prclass=predict(ldadat, data[,1:7])$class
st=data[data$CLASS!=prclass,]
acc=1-nrow(st)/nrow(data)
cat("Точность классификации:",acc,'\n')
if(near(acc,1)) break
if(nrow(st)==1){
number.of.max.distance=1
}else{
distances=c()
for(i in 1:nrow(st)){
cls=as.numeric(st[i,8])
vec=(means[cls,]-as.numeric(st[i,1:7]))
if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
library(factoextra)
print( fviz_cluster(list(data[,1:7],data[,8]), data[, -8], ellipse.type = "norm"))
library(factoextra)
print( fviz_cluster(list(data=data[,1:7],cluster=data[,8]), ellipse.type = "norm"))
showimage(){
library(factoextra)
print( fviz_cluster(list(data=data[,1:7],cluster=data[,8]), ellipse.type = "norm"))
}
showimage=function(){
library(factoextra)
print( fviz_cluster(list(data=data[,1:7],cluster=data[,8]), ellipse.type = "norm"))
}
acc=0#точность
repeat{
#for(k in 1:40){
#showfaces()
showimage()
ldadat <- lda(CLASS~.,data,method="moment")
means=ldadat$means
cov.mat=covinv(data)
#для всех неправильно найденных найти расстояния до кластеров, отнесённых экспертами
prclass=predict(ldadat, data[,1:7])$class
st=data[data$CLASS!=prclass,]
acc=1-nrow(st)/nrow(data)
cat("Точность классификации:",acc,'\n')
if(near(acc,1)) break
if(nrow(st)==1){
number.of.max.distance=1
}else{
distances=c()
for(i in 1:nrow(st)){
cls=as.numeric(st[i,8])
vec=(means[cls,]-as.numeric(st[i,1:7]))
if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
###################################Задание 4
data =data.frame(read_excel("Приложение 2.xlsx"))
data$CLASS=factor(data$CLASS)
pairs(data[,1:7],col=data$CLASS,pch=16)
acc=0#точность
repeat{
#for(k in 1:40){
#showfaces()
showimage()
ldadat <- lda(CLASS~.,data,method="moment")
means=ldadat$means
cov.mat=covinv(data)
#для всех неправильно найденных найти расстояния до кластеров, отнесённых экспертами
prclass=predict(ldadat, data[,1:7])$class
st=data[data$CLASS!=prclass,]
acc=1-nrow(st)/nrow(data)
cat("Точность классификации:",acc,'\n')
if(near(acc,1)) break
if(nrow(st)==1){
number.of.max.distance=1
}else{
distances=c()
for(i in 1:nrow(st)){
cls=as.numeric(st[i,8])
vec=(means[cls,]-as.numeric(st[i,1:7]))
if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
Out_CTab(ldadat,data$CLASS)
# Функция вывода результатов классификации
Out_CTab <- function(model, group) {
cat("Таблица неточностей \"Факт/Прогноз\" по обучающей выборке: \n")
classified <- predict(model)$class
t1 <- table(group, classified)
print(t1)
# Точность классификации и расстояние Махалонобиса
Err_S <- mean(group != classified)
mahDist <- dist(model$means %*% model$scaling)
cat("Точность классификации:",1-Err_S[1],'\n')
cat("Расстояния Махалонобиса:\n")
print(mahDist)
# Таблица "Факт/Прогноз" и ошибка при скользящем контроле
t2 <-  table(group, update(model, CV = T)$class -> LDA.cv)
Err_CV <- mean(group != LDA.cv)
cat("Ошибка при скользящем контроле:",Err_CV[1],'\n')
Err_S.MahD <- c(Err_S, mahDist)
Err_CV.N <- c(Err_CV, length(group))
cbind(t1, Err_S.MahD, t2, Err_CV.N)
cat("Результаты многомерного дисперсионного анализа: \n")
ldam <- manova(as.matrix( data[,1:7]) ~ data$CLASS)
print(summary(ldam, test="Wilks"))
}
Out_CTab(ldadat,data$CLASS)
pairs(data[,1:7],col=data$CLASS,pch=16)
#номер варианта
nv=7
#чтение данных и чистка
library(readxl)
datacrude =data.frame(read_excel("Таблица 1.xlsx")) #считывание таблицы
data=datacrude[5:nrow(datacrude),-1]#удаление лишних строк и столбцов
data=data[-nv,]#удаление строки в соответствиии с номером варианта
colnames(data)=c("Country","Doctors","Deaths","GDP","Costs")#переименование столбцов
data[,2:5]=apply(data[,2:5],2,function(x)scale(as.numeric(x)))#тут переменные из текста преобразуются в числа и стандартизируются
data[,1]=factor(data[,1])#первая переменная из количественной преобразуется в номенативную
#####################################Задание 1
d = dist(data[,2:5], method = "euclidean")#матрица расстояний
fit <- hclust(d, method = "ward.D")
plot(fit, labels = data$Country,xlab = "Countries")
plot(fit$height, xlab = "step",ylab="dist",type="b",col="blue",lwd=1,main="Расстояния при объединении кластеров")
mat=fit$merge
resu=list()
countries=as.character(data$Country)
for(i in 1:nrow(mat)){
if(mat[i,1]<0){
a=countries[-mat[i,1]]
}else{
a=as.character(resu[[mat[i,1]]])
}
if(mat[i,2]<0){
b=countries[-mat[i,2]]
}else{
b=as.character(resu[[mat[i,2]]])
}
resu[[i]]=c(a,b)
}
names(resu)=paste("Шаг",1:nrow(mat),"расстояние", fit$height)
print(resu)
library(dplyr)
###################################Задание 4
data =data.frame(read_excel("Приложение 2.xlsx"))
data$CLASS=factor(data$CLASS)
pairs(data[,1:7],col=data$CLASS,pch=16)
showfaces=function(){
newdata=as_data_frame(data)%>%group_by(CLASS)%>%
summarise_all(funs(mean))
print(faces(newdata[,2:8]))#рисуем лица
}
showfaces()
showimage=function(){
library(factoextra)
print( fviz_cluster(list(data=data[,1:7],cluster=data[,8]), ellipse.type = "norm"))
}
library(MASS)
# Функция вывода результатов классификации
Out_CTab <- function(model, group) {
cat("Таблица неточностей \"Факт/Прогноз\" по обучающей выборке: \n")
classified <- predict(model)$class
t1 <- table(group, classified)
print(t1)
# Точность классификации и расстояние Махалонобиса
Err_S <- mean(group != classified)
mahDist <- dist(model$means %*% model$scaling)
cat("Точность классификации:",1-Err_S[1],'\n')
cat("Расстояния Махалонобиса:\n")
print(mahDist)
# Таблица "Факт/Прогноз" и ошибка при скользящем контроле
t2 <-  table(group, update(model, CV = T)$class -> LDA.cv)
Err_CV <- mean(group != LDA.cv)
cat("Ошибка при скользящем контроле:",Err_CV[1],'\n')
Err_S.MahD <- c(Err_S, mahDist)
Err_CV.N <- c(Err_CV, length(group))
cbind(t1, Err_S.MahD, t2, Err_CV.N)
cat("Результаты многомерного дисперсионного анализа: \n")
ldam <- manova(as.matrix( data[,1:7]) ~ data$CLASS)
print(summary(ldam, test="Wilks"))
}
#линейный дискриминантный анализ
ldadat <- lda(CLASS~.,data,method="moment")
Out_CTab(ldadat,data$CLASS)
#матрицы, обратные матрицам ковариации для каждого класса
covinv=function(df){
res=list()
for(i in 1:length(levels(df$CLASS)))
res[[i]]= tryCatch({df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve},error=function(r) NA)
#res[[i]]=df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve
res
}
#расстояния Махаланобиса от элемента до каждого из классов
distance=function(means,covs, elem){
res=c()
for(i in 1:nrow(means)){
vec=(means[i,]-elem)
res[i]=(vec%*%covs[[i]])%*%vec
}
return(sqrt(res))
}
#поиск номера элемента в датафрейме
find.number=function(df,elem){
sm=0
i=0
len=length(elem)
while (sm!=len) {
i=i+1
v=ifelse(df[i,]==elem,T,F)
sm=sum(v)
}
return(i)
}
acc=0#точность
repeat{
#for(k in 1:40){
#showfaces()
showimage()
ldadat <- lda(CLASS~.,data,method="moment")
means=ldadat$means
cov.mat=covinv(data)
#для всех неправильно найденных найти расстояния до кластеров, отнесённых экспертами
prclass=predict(ldadat, data[,1:7])$class
st=data[data$CLASS!=prclass,]
acc=1-nrow(st)/nrow(data)
cat("Точность классификации:",acc,'\n')
if(near(acc,1)) break
if(nrow(st)==1){
number.of.max.distance=1
}else{
distances=c()
for(i in 1:nrow(st)){
cls=as.numeric(st[i,8])
vec=(means[cls,]-as.numeric(st[i,1:7]))
if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
ldadat$means#групповые средние
(mat=ldadat$scaling)#матрица дискриминантных функций
plot(ldadat)
#линейный дискриминантный анализ
ldadat <- lda(CLASS~.,data,method="moment")
###################################Задание 4
data =data.frame(read_excel("Приложение 2.xlsx"))
data$CLASS=factor(data$CLASS)
pairs(data[,1:7],col=data$CLASS,pch=16)
#лица Чернова
showfaces=function(){
newdata=as_data_frame(data)%>%group_by(CLASS)%>%
summarise_all(funs(mean))
print(faces(newdata[,2:8]))#рисуем лица
}
showfaces()
#визуализация кластеров через главные компоненты
showimage=function(){
library(factoextra)
print( fviz_cluster(list(data=data[,1:7],cluster=data[,8]), ellipse.type = "norm"))
}
#проверка многомерного нормального распределения по каждому классу
tmp=numeric()
library(mvnormtest)
for(i in 1:length(levels(data$CLASS))){
tmp[i]=mshapiro.test(t(data[data$CLASS == i, 1:7]))$p.value
}
library(MASS)
# Функция вывода результатов классификации
Out_CTab <- function(model, group) {
cat("Таблица неточностей \"Факт/Прогноз\" по обучающей выборке: \n")
classified <- predict(model)$class
t1 <- table(group, classified)
print(t1)
# Точность классификации и расстояние Махалонобиса
Err_S <- mean(group != classified)
mahDist <- dist(model$means %*% model$scaling)
cat("Точность классификации:",1-Err_S[1],'\n')
cat("Расстояния Махалонобиса:\n")
print(mahDist)
# Таблица "Факт/Прогноз" и ошибка при скользящем контроле
t2 <-  table(group, update(model, CV = T)$class -> LDA.cv)
Err_CV <- mean(group != LDA.cv)
cat("Ошибка при скользящем контроле:",Err_CV[1],'\n')
Err_S.MahD <- c(Err_S, mahDist)
Err_CV.N <- c(Err_CV, length(group))
cbind(t1, Err_S.MahD, t2, Err_CV.N)
cat("Результаты многомерного дисперсионного анализа: \n")
ldam <- manova(as.matrix( data[,1:7]) ~ data$CLASS)
print(summary(ldam, test="Wilks"))
}
#линейный дискриминантный анализ
ldadat <- lda(CLASS~.,data,method="moment")
Out_CTab(ldadat,data$CLASS)
Out_CTab(ldadat,data$CLASS)
ldadat$means#групповые средние
(mat=ldadat$scaling)#матрица дискриминантных функций
plot(ldadat)
#матрицы, обратные матрицам ковариации для каждого класса
covinv=function(df){
res=list()
for(i in 1:length(levels(df$CLASS)))
res[[i]]= tryCatch({df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve},error=function(r) NA)
#res[[i]]=df[df$CLASS==i,1:7] %>% as.matrix() %>% cov() %>% solve
res
}
#расстояния Махаланобиса от элемента до каждого из классов
distance=function(means,covs, elem){
res=c()
for(i in 1:nrow(means)){
vec=(means[i,]-elem)
res[i]=(vec%*%covs[[i]])%*%vec
}
return(sqrt(res))
}
#поиск номера элемента в датафрейме
find.number=function(df,elem){
sm=0
i=0
len=length(elem)
while (sm!=len) {
i=i+1
v=ifelse(df[i,]==elem,T,F)
sm=sum(v)
}
return(i)
}
acc=0#точность
repeat{
#for(k in 1:40){
#showfaces()
showimage()
ldadat <- lda(CLASS~.,data,method="moment")
means=ldadat$means
cov.mat=covinv(data)
#для всех неправильно найденных найти расстояния до кластеров, отнесённых экспертами
prclass=predict(ldadat, data[,1:7])$class
st=data[data$CLASS!=prclass,]
acc=1-nrow(st)/nrow(data)
cat("Точность классификации:",acc,'\n')
if(near(acc,1)) break
if(nrow(st)==1){
number.of.max.distance=1
}else{
distances=c()
for(i in 1:nrow(st)){
cls=as.numeric(st[i,8])
vec=(means[cls,]-as.numeric(st[i,1:7]))
if(is.na(cov.mat[[cls]])){
distances[i]=NA
}else{
distances[i]=(vec%*%cov.mat[[cls]])%*%vec
}
}
distances=sqrt(distances)
#номер элемента (в таблице неверно отнесённых) с максимальным расстоянием для своего кластера
number.of.max.distance=which.max(distances)
}
tt=st[number.of.max.distance,]#сам элемент
cat("Неправильно отнесённый элемент с максимальным расстоянием (",max(distances,na.rm = T),")\n")
#номер того же элемента, но в исходном фрейме
number.of.max.distance.new=find.number(data,tt)
print(data[number.of.max.distance.new,])
#сделать замену на кластер с минимальным расстоянием
data[number.of.max.distance.new,8]=predict(ldadat, tt[,1:7])$class#levels(data$CLASS)[which.min(distance(ldadat$means,cov.mat,as.numeric(tt[,-8])))]
cat("Заменяется на\n")
print(data[number.of.max.distance.new,])
}
#дерево классификации
library(tree)
datatree <- tree(data[,8] ~ ., data[,-8])
plot(datatree)
text(datatree)
knitr::opts_chunk$set(echo = TRUE,include = TRUE,tidy = TRUE,cache = FALSE,eval = TRUE, message = FALSE,warning = FALSE,fig.align = "center")
rf=lda(CLASS~.,data,method="moment")#фиксируется модель для следующего задания
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric)
data2=data2[31:80,]
(cluster=predict(rf, data2))
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric)
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric) %>% data_frame()
data2 =data.frame(read_excel("Приложение 3.xlsx"))
View(data2)
apply(data2,2,as.numeric)
apply(data2,2,as.numeric) %>% as_data_frame()
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric) %>% as_data_frame()
data2=data2[31:80,]
(cluster=predict(rf, data2))
data2=data.frame(cbind(data2,cluster))
data2$cluster=factor(data2$cluster)
cluster=predict(rf, data2)$cluster
cluster=predict(rf, data2)$class
data2=data.frame(cbind(data2,cluster))
data2$cluster=factor(data2$cluster)
View(data2)
View(data2)
data2 =data.frame(read_excel("Приложение 3.xlsx"))
data2= apply(data2,2,as.numeric) %>% as_data_frame()
data2=data2[31:80,]
(cluster=predict(rf, data2)$class)
data2=data.frame(cbind(data2,cluster))
data2$cluster=factor(data2$cluster)
newdata=as_data_frame(data2)%>%group_by(cluster)%>%
summarise_all(funs(mean))
View(newdata)
View(data)
faces(newdata[,2:8])#рисуем лица
View(newdata)
unlink('Многомерная статистика_cache', recursive = TRUE)
unlink('Многомерная статистика_cache', recursive = TRUE)
